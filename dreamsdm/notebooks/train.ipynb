{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20c90981-1328-44a8-85ad-432fee12bdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# from torchvision.models import resnet18, ResNet18_Weights\n",
    "import torch.nn as nn\n",
    "\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c14777a-f1ff-4776-a335-ff75189deed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7d7bc80-e46f-4b26-b1ab-118514f67dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class WDMGalaxiesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    file_path: path to hdf file\n",
    "    dataset_name: specify train or test datasets\n",
    "    transform, target_transforms: optional transforms\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_path, dataset_name, transform = None,\n",
    "                 target_transform = None):\n",
    "        self.file_path = file_path\n",
    "        self.dataset_name = dataset_name\n",
    "        self.transform = transform \n",
    "        self.target_transform = target_transform\n",
    "        self.length = None\n",
    "        self._idx_to_name = {} #data_dict \n",
    "\n",
    "        with h5py.File(self.file_path, 'r') as hf:\n",
    "            for gname, group in hf.items():\n",
    "                if gname == self.dataset_name:\n",
    "                    sample_id_idx = 0\n",
    "                    for sim_id, dd in (group.items()):\n",
    "                        for Mgas_id, ee in enumerate(dd.items()):\n",
    "                            self._idx_to_name[sample_id_idx] = [sim_id, ee[0]]\n",
    "                            sample_id_idx+=1 \n",
    "                    self.length = sample_id_idx\n",
    "        # print(self._idx_to_name)\n",
    "\n",
    "    def __len__(self):\n",
    "        assert self.length is not None\n",
    "        return self.length\n",
    "    \n",
    "    def _open_hdf5(self):\n",
    "        self._hf = h5py.File(self.file_path, 'r')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # if (torch.is_tensor(idx)):\n",
    "        #     idx = idx.tolist()\n",
    "        if not hasattr(self, '_hf'):\n",
    "            self._open_hdf5()\n",
    "\n",
    "        sim_id, Mgas_id = self._idx_to_name[idx]\n",
    "        data = self._hf[self.dataset_name][sim_id][Mgas_id]\n",
    "        image = np.array(data)\n",
    "        # label = torch.tensor(data.attrs['WDM'])\n",
    "        label = torch.tensor(self._hf[self.dataset_name][sim_id].attrs['WDM'])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # if self.target_transform:\n",
    "            # label = self.target_transform(label)\n",
    "\n",
    "        return image, label\n",
    "# import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de080903-9751-4671-aeba-28f959dc6a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x155549ba0210>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28afe0a0-760a-4d4c-8f1e-36d5b0eae747",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNNRegression(nn.Module):\n",
    "    def __init__(self, image_size = (1, 512, 512)):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.image_size = image_size\n",
    "        self.conv1 = nn.Conv2d(in_channels=self.image_size[0], out_channels=4, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=4, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.linear_line_size = int(16*(image_size[1]//4)*(image_size[2]//4))\n",
    "        self.fc1 = nn.Linear(in_features=self.linear_line_size, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        print('Size of tensor after each layer')\n",
    "        print(f'conv1 {x.size()}')\n",
    "        x = nn.functional.relu(x)\n",
    "        print(f'relu1 {x.size()}')\n",
    "        x = self.pool1(x)\n",
    "        print(f'pool1 {x.size()}')\n",
    "        x = self.conv2(x)\n",
    "        print(f'conv2 {x.size()}')\n",
    "        x = nn.functional.relu(x)\n",
    "        print(f'relu2 {x.size()}')\n",
    "        x = self.pool2(x)\n",
    "        print(f'pool2 {x.size()}')\n",
    "        x = x.view(-1, self.linear_line_size)\n",
    "        print(f'view1 {x.size()}')\n",
    "        x = self.fc1(x)\n",
    "        print(f'fc1 {x.size()}')\n",
    "        x = nn.functional.relu(x)\n",
    "        print(f'relu2 {x.size()}')\n",
    "        x = self.fc2(x)\n",
    "        print(f'fc2 {x.size()}')\n",
    "        return x\n",
    "       \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfbc4f22-5106-43ce-9118-e53f3d9f2464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "img_dir =  \"/mnt/ceph/users/dmohan/dreams/data/dreams/mwzooms_test.hdf5\"\n",
    "\n",
    "mu = 498244.\n",
    "sigma = 1235061.2500\n",
    "\n",
    "transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean = mu, std = sigma)])\n",
    "\n",
    "trainset = WDMGalaxiesDataset(img_dir, 'Train', transforms) \n",
    "valset = WDMGalaxiesDataset(img_dir, 'Val', transforms)\n",
    "testset = WDMGalaxiesDataset(img_dir, 'Test', transforms)\n",
    "\n",
    "print(len(trainset))\n",
    "print(len(valset))\n",
    "print(len(testset))\n",
    "\n",
    "train_dataloader = DataLoader(trainset, batch_size=2, shuffle=True, num_workers = 1)\n",
    "val_dataloader = DataLoader(valset, batch_size=2, shuffle=True, num_workers = 1)\n",
    "test_dataloader = DataLoader(testset, batch_size=2, shuffle=True, num_workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8ceb20e-9cf9-42de-9773-cd8e4b6ea320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNRegression(\n",
      "  (conv1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=262144, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CNNRegression(image_size = (1, 512, 512)).to(device)\n",
    "print(model)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d6d0022-5f98-4150-96c2-20305f6425bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 512])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.zeros((1, 512, 512))\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c868829-c2cf-4967-9165-c7bc5d32133a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of tensor after each layer\n",
      "conv1 torch.Size([4, 512, 512])\n",
      "relu1 torch.Size([4, 512, 512])\n",
      "pool1 torch.Size([4, 256, 256])\n",
      "conv2 torch.Size([16, 256, 256])\n",
      "relu2 torch.Size([16, 256, 256])\n",
      "pool2 torch.Size([16, 128, 128])\n",
      "view1 torch.Size([1, 262144])\n",
      "fc1 torch.Size([1, 128])\n",
      "relu2 torch.Size([1, 128])\n",
      "fc2 torch.Size([1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0094]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(t.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a04f40b0-a1a4-463c-9613-b4abf0dc1b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_loader, device):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, (x_train, y_train) in enumerate(train_loader):\n",
    "        x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_train)\n",
    "        print(outputs.flatten(), y_train)\n",
    "        loss = criterion(outputs.to(torch.double), y_train)\n",
    "        # print(outputs.to(torch.double).dtype, y_train.dtype)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4df1962a-5289-4645-9281-0932ade84794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of tensor after each layer\n",
      "conv1 torch.Size([2, 4, 512, 512])\n",
      "relu1 torch.Size([2, 4, 512, 512])\n",
      "pool1 torch.Size([2, 4, 256, 256])\n",
      "conv2 torch.Size([2, 16, 256, 256])\n",
      "relu2 torch.Size([2, 16, 256, 256])\n",
      "pool2 torch.Size([2, 16, 128, 128])\n",
      "view1 torch.Size([2, 262144])\n",
      "fc1 torch.Size([2, 128])\n",
      "relu2 torch.Size([2, 128])\n",
      "fc2 torch.Size([2, 1])\n",
      "tensor([ 63066.0352, 257999.6094], device='cuda:0', grad_fn=<ViewBackward0>) tensor([0.1912, 0.1130], device='cuda:0', dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not load library libcudnn_cnn_train.so.8. Error: libcudnn_cnn_train.so.8: cannot open shared object file: No such file or directory\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: libcudnn_cnn_train.so.8: cannot open shared object file: No such file or directory\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: libcudnn_cnn_train.so.8: cannot open shared object file: No such file or directory\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: libcudnn_cnn_train.so.8: cannot open shared object file: No such file or directory\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: libcudnn_cnn_train.so.8: cannot open shared object file: No such file or directory\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: libcudnn_cnn_train.so.8: cannot open shared object file: No such file or directory\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: libcudnn_cnn_train.so.8: cannot open shared object file: No such file or directory\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: libcudnn_cnn_train.so.8: cannot open shared object file: No such file or directory\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: libcudnn_cnn_train.so.8: cannot open shared object file: No such file or directory\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: libcudnn_cnn_train.so.8: cannot open shared object file: No such file or directory\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: libcudnn_cnn_train.so.8: cannot open shared object file: No such file or directory\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: libcudnn_cnn_train.so.8: cannot open shared object file: No such file or directory\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: libcudnn_cnn_train.so.8: cannot open shared object file: No such file or directory\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: libcudnn_cnn_train.so.8: cannot open shared object file: No such file or directory\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: libcudnn_cnn_train.so.8: cannot open shared object file: No such file or directory\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: libcudnn_cnn_train.so.8: cannot open shared object file: No such file or directory\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: libcudnn_cnn_train.so.8: cannot open shared object file: No such file or directory\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: libcudnn_cnn_train.so.8: cannot open shared object file: No such file or directory\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "GET was unable to find an engine to execute this computation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      5\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 6\u001b[0m     avg_loss_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     train_loss[epoch] \u001b[38;5;241m=\u001b[39m avg_loss_train\n",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, train_loader, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mdouble), y_train)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# print(outputs.to(torch.double).dtype, y_train.dtype)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     13\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/sw/nix/store/71ksmx7k6xy3v9ksfkv5mp5kxxp64pd6-python-3.10.13-view/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: GET was unable to find an engine to execute this computation"
     ]
    }
   ],
   "source": [
    "#training loop\n",
    "epochs = 10\n",
    "train_loss = np.zeros(epochs)\n",
    "for epoch in range(epochs):\n",
    "    model.train(True)\n",
    "    avg_loss_train = train(model, optimizer, criterion, train_dataloader, device)\n",
    "    train_loss[epoch] = avg_loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "079087d5-37f4-4fbc-bf17-5db3fd6328cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct  8 17:03:35 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           Off |   00000000:1C:00.0 Off |                    0 |\n",
      "| N/A   30C    P0             57W /  300W |     744MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A    501137      C   ...han/dreams-dm/venv/venvn/bin/python        740MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfdab51d-e740-4466-90db-9cfd604c0f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.3\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ea60ded-10da-46c5-9423-4df952c83690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch. __version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc00a20d-405e-40f3-a8f0-82e26e83f341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3eb80487-e3ce-4f00-bb0f-9a898a18a8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: module: command not found\n"
     ]
    }
   ],
   "source": [
    "!module load cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f31552b-4915-4f01-9588-3ec95935f23d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmkernel",
   "language": "python",
   "name": "dmkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
